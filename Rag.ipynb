{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25eb54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 150 Entries\n"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "\n",
    "dataset = []\n",
    "with open('cat-facts.txt','r',encoding=\"utf-8\") as file:\n",
    "    dataset= file.readlines()\n",
    "    print(f\"Loaded {len(dataset)} Entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d540ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EMBEDDING_MODEL = 'hf.co/CompendiumLabs/bge-base-en-v1.5-gguf'\n",
    "LANGUAGE_MODEL = 'hf.co/bartowski/Llama-3.2-1B-Instruct-GGUF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a6d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB = []\n",
    "def add_chunks_to_database(chunks):\n",
    "    embedding = ollama.embed(model= EMBEDDING_MODEL,input=chunks)['embeddings'][0]\n",
    "    VECTOR_DB.append((chunks,embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8bafe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 1/150 to database\n",
      "Added 2/150 to database\n",
      "Added 3/150 to database\n",
      "Added 4/150 to database\n",
      "Added 5/150 to database\n",
      "Added 6/150 to database\n",
      "Added 7/150 to database\n",
      "Added 8/150 to database\n",
      "Added 9/150 to database\n",
      "Added 10/150 to database\n",
      "Added 11/150 to database\n",
      "Added 12/150 to database\n",
      "Added 13/150 to database\n",
      "Added 14/150 to database\n",
      "Added 15/150 to database\n",
      "Added 16/150 to database\n",
      "Added 17/150 to database\n",
      "Added 18/150 to database\n",
      "Added 19/150 to database\n",
      "Added 20/150 to database\n",
      "Added 21/150 to database\n",
      "Added 22/150 to database\n",
      "Added 23/150 to database\n",
      "Added 24/150 to database\n",
      "Added 25/150 to database\n",
      "Added 26/150 to database\n",
      "Added 27/150 to database\n",
      "Added 28/150 to database\n",
      "Added 29/150 to database\n",
      "Added 30/150 to database\n",
      "Added 31/150 to database\n",
      "Added 32/150 to database\n",
      "Added 33/150 to database\n",
      "Added 34/150 to database\n",
      "Added 35/150 to database\n",
      "Added 36/150 to database\n",
      "Added 37/150 to database\n",
      "Added 38/150 to database\n",
      "Added 39/150 to database\n",
      "Added 40/150 to database\n",
      "Added 41/150 to database\n",
      "Added 42/150 to database\n",
      "Added 43/150 to database\n",
      "Added 44/150 to database\n",
      "Added 45/150 to database\n",
      "Added 46/150 to database\n",
      "Added 47/150 to database\n",
      "Added 48/150 to database\n",
      "Added 49/150 to database\n",
      "Added 50/150 to database\n",
      "Added 51/150 to database\n",
      "Added 52/150 to database\n",
      "Added 53/150 to database\n",
      "Added 54/150 to database\n",
      "Added 55/150 to database\n",
      "Added 56/150 to database\n",
      "Added 57/150 to database\n",
      "Added 58/150 to database\n",
      "Added 59/150 to database\n",
      "Added 60/150 to database\n",
      "Added 61/150 to database\n",
      "Added 62/150 to database\n",
      "Added 63/150 to database\n",
      "Added 64/150 to database\n",
      "Added 65/150 to database\n",
      "Added 66/150 to database\n",
      "Added 67/150 to database\n",
      "Added 68/150 to database\n",
      "Added 69/150 to database\n",
      "Added 70/150 to database\n",
      "Added 71/150 to database\n",
      "Added 72/150 to database\n",
      "Added 73/150 to database\n",
      "Added 74/150 to database\n",
      "Added 75/150 to database\n",
      "Added 76/150 to database\n",
      "Added 77/150 to database\n",
      "Added 78/150 to database\n",
      "Added 79/150 to database\n",
      "Added 80/150 to database\n",
      "Added 81/150 to database\n",
      "Added 82/150 to database\n",
      "Added 83/150 to database\n",
      "Added 84/150 to database\n",
      "Added 85/150 to database\n",
      "Added 86/150 to database\n",
      "Added 87/150 to database\n",
      "Added 88/150 to database\n",
      "Added 89/150 to database\n",
      "Added 90/150 to database\n",
      "Added 91/150 to database\n",
      "Added 92/150 to database\n",
      "Added 93/150 to database\n",
      "Added 94/150 to database\n",
      "Added 95/150 to database\n",
      "Added 96/150 to database\n",
      "Added 97/150 to database\n",
      "Added 98/150 to database\n",
      "Added 99/150 to database\n",
      "Added 100/150 to database\n",
      "Added 101/150 to database\n",
      "Added 102/150 to database\n",
      "Added 103/150 to database\n",
      "Added 104/150 to database\n",
      "Added 105/150 to database\n",
      "Added 106/150 to database\n",
      "Added 107/150 to database\n",
      "Added 108/150 to database\n",
      "Added 109/150 to database\n",
      "Added 110/150 to database\n",
      "Added 111/150 to database\n",
      "Added 112/150 to database\n",
      "Added 113/150 to database\n",
      "Added 114/150 to database\n",
      "Added 115/150 to database\n",
      "Added 116/150 to database\n",
      "Added 117/150 to database\n",
      "Added 118/150 to database\n",
      "Added 119/150 to database\n",
      "Added 120/150 to database\n",
      "Added 121/150 to database\n",
      "Added 122/150 to database\n",
      "Added 123/150 to database\n",
      "Added 124/150 to database\n",
      "Added 125/150 to database\n",
      "Added 126/150 to database\n",
      "Added 127/150 to database\n",
      "Added 128/150 to database\n",
      "Added 129/150 to database\n",
      "Added 130/150 to database\n",
      "Added 131/150 to database\n",
      "Added 132/150 to database\n",
      "Added 133/150 to database\n",
      "Added 134/150 to database\n",
      "Added 135/150 to database\n",
      "Added 136/150 to database\n",
      "Added 137/150 to database\n",
      "Added 138/150 to database\n",
      "Added 139/150 to database\n",
      "Added 140/150 to database\n",
      "Added 141/150 to database\n",
      "Added 142/150 to database\n",
      "Added 143/150 to database\n",
      "Added 144/150 to database\n",
      "Added 145/150 to database\n",
      "Added 146/150 to database\n",
      "Added 147/150 to database\n",
      "Added 148/150 to database\n",
      "Added 149/150 to database\n",
      "Added 150/150 to database\n"
     ]
    }
   ],
   "source": [
    "for i ,chunk in enumerate(dataset):\n",
    "    add_chunks_to_database(chunk)\n",
    "    print(f\"Added {i+1}/{len(dataset)} to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7490a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a,b):\n",
    "    dot_product = sum([x*y for x,y in zip(a,b)])\n",
    "    norm_a = sum([x**2 for x in a])**0.5\n",
    "    norm_b = sum([y**2 for y in b])**0.5\n",
    "    return dot_product /(norm_a * norm_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03140db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query,top_n=3):\n",
    "    query_embedding = ollama.embed(model=EMBEDDING_MODEL,input=query)['embeddings'][0]\n",
    "    similarities =[]\n",
    "    for chunk,embedding in VECTOR_DB:\n",
    "        similarity = cosine_similarity(query_embedding,embedding)\n",
    "        similarities.append((chunk, similarity))\n",
    "        similarities.sort(key=lambda x:x[1],reverse=True)\n",
    "        return similarities[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6422ba7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieved knowledge:\n",
      " - (similarity: 0.34) On average, cats spend 2/3 of every day sleeping. That means a nine-year-old cat has been awake for only three years of its life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chatbot input\n",
    "input_query = input(\"Ask your question: \")\n",
    "\n",
    "# Retrieve relevant knowledge\n",
    "retrieved_knowledge = retrieve(input_query)\n",
    "print(\"\\nRetrieved knowledge:\")\n",
    "for chunk, similarity in retrieved_knowledge:\n",
    "    print(f\" - (similarity: {similarity:.2f}) {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "814eceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "context_text = '\\n'.join([f' - {chunk.strip()}' for chunk, _ in retrieved_knowledge])\n",
    "instruction_prompt = f'''You are a helpful chatbot.\n",
    "Use only the following pieces of context to answer the question. Don't make up any new information:\n",
    "{context_text}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4891f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with Ollama\n",
    "stream = ollama.chat(\n",
    "    model=LANGUAGE_MODEL,\n",
    "    messages=[\n",
    "        {'role': 'system', 'content': instruction_prompt},\n",
    "        {'role': 'user', 'content': input_query}\n",
    "    ],\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f87ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chatbot Response:\n",
      "A cat! A small, furry, and often adorable creature that brings joy to many people's lives."
     ]
    }
   ],
   "source": [
    "print(\"\\nChatbot Response:\")\n",
    "for chunk in stream:\n",
    "    print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1abff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
